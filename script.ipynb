{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durability A: 19.48451680194802 Durability B: 16.08285004932388 Durability C: 28.170285788105236\n",
      "total shuttles used in simulation = 214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from statsmodels.regression.linear_model import RegressionResultsWrapper\n",
    "\n",
    "raw_data = [\"A\",] *33 + [\"B\",] * 33 + [\"C\",] * 33\n",
    "shuttles_used = [np.random.choice([1, 2, 3]) for _ in range(len(raw_data))]\n",
    "#define true durability\n",
    "def get_true_durability(cat):\n",
    "    return {'A': 21, 'B': 17, 'C': 27}.get(cat)\n",
    "data_noise = {\n",
    "    'category': raw_data,\n",
    "    'points_played': [(get_true_durability(cat)+ np.random.normal(0,5))*used for cat,used in zip(raw_data,shuttles_used)],\n",
    "    \"shuttles_used\": shuttles_used\n",
    "}\n",
    "\n",
    "df_noise = pd.DataFrame(data_noise)\n",
    "df_noise[\"durability\"] = df_noise[\"points_played\"] / df_noise[\"shuttles_used\"]\n",
    "\n",
    "\n",
    "df_noise[\"category\"] = pd.Categorical(df_noise[\"category\"])\n",
    "\n",
    "formula = 'durability ~ C(category)'\n",
    "model: RegressionResultsWrapper = smf.wls(formula, data=df_noise, weights=df_noise[\"shuttles_used\"]).fit() #weighted least squares\n",
    "# print(model.summary())\n",
    "durability_A = model.params[\"Intercept\"]\n",
    "durability_B = model.params[\"C(category)[T.B]\"] + durability_A\n",
    "durability_C = model.params[\"C(category)[T.C]\"] + durability_A\n",
    "print(f\"Durability A: {durability_A}\", \n",
    "      f\"Durability B: {durability_B}\",\n",
    "      f\"Durability C: {durability_C}\")\n",
    "\n",
    "print(f\"total shuttles used in simulation = {df_noise['shuttles_used'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient evidence that Durability B is at least 2 units larger than Durability A\n",
      "Insufficient evidence that Durability A is at least 2 units larger than Durability B\n",
      "Durability C is at least 2 units larger than Durability A\n",
      "Insufficient evidence that Durability A is at least 2 units larger than Durability C\n",
      "Durability C is at least 2 units larger than Durability B\n",
      "Insufficient evidence that Durability B is at least 2 units larger than Durability C\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "def test_durability_difference(model, category1, category2, test_value=1, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test if the durability difference between two categories is at least a given value.\n",
    "    \n",
    "    H0: durability1 - durability2 â‰¤ test_value\n",
    "    H1: durability1 - durability2 > test_value\n",
    "\n",
    "    Parameters:\n",
    "    - model: RegressionResultsWrapper, the fitted model\n",
    "    - category1: str, the first category (e.g., 'A')\n",
    "    - category2: str, the second category (e.g., 'B')\n",
    "    - test_value: float, the value to test against (default: 1)\n",
    "    - alpha: float, significance level (default: 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - dict: containing the test results\n",
    "    \"\"\"\n",
    "    # Quick check for same category - can't have a meaningful difference\n",
    "    if category1 == category2:\n",
    "        return {\n",
    "            \"difference\": 0,\n",
    "            \"t_stat\": float('nan'),\n",
    "            \"p_value\": 1.0,  # Maximum p-value means no evidence against H0\n",
    "            \"reject_h0\": False,\n",
    "            \"conclusion\": f\"Categories are the same, difference is exactly 0\"\n",
    "        }\n",
    "    \n",
    "    # Get the parameter estimates for the categories\n",
    "    durability1 = model.params[\"Intercept\"] if category1 == \"A\" else model.params[f\"C(category)[T.{category1}]\"] + model.params[\"Intercept\"]\n",
    "    durability2 = model.params[\"Intercept\"] if category2 == \"A\" else model.params[f\"C(category)[T.{category2}]\"] + model.params[\"Intercept\"]\n",
    "\n",
    "    # Calculate the difference\n",
    "    diff = durability1 - durability2\n",
    "\n",
    "    # Get the covariance matrix\n",
    "    cov = model.cov_params()\n",
    "\n",
    "    # Create the contrast vector\n",
    "    contrast = np.zeros(len(model.params))\n",
    "    \n",
    "    # For category1\n",
    "    if category1 == \"A\":\n",
    "        contrast[0] = 1  # Intercept\n",
    "    else:\n",
    "        contrast[0] = 1  # Intercept component\n",
    "        contrast[model.params.index.get_loc(f\"C(category)[T.{category1}]\")] = 1\n",
    "    \n",
    "    # For category2\n",
    "    if category2 == \"A\":\n",
    "        contrast[0] -= 1  # Subtract from Intercept\n",
    "    else:\n",
    "        contrast[0] -= 1  # Subtract Intercept component\n",
    "        contrast[model.params.index.get_loc(f\"C(category)[T.{category2}]\")] = -1\n",
    "\n",
    "    # Standard error of the difference\n",
    "    se_diff = np.sqrt(contrast.T @ cov @ contrast)\n",
    "\n",
    "    # Calculate t-statistic for testing if difference > test_value\n",
    "    t_stat = (diff - test_value) / se_diff\n",
    "\n",
    "    # Calculate p-value (one-sided test, upper tail)\n",
    "    p_value = 1 - stats.t.cdf(t_stat, df=model.df_resid)\n",
    "\n",
    "    # Conclusion\n",
    "    reject_h0 = p_value < alpha\n",
    "\n",
    "    return {\n",
    "        \"difference\": diff,\n",
    "        \"test_value\": test_value,\n",
    "        \"standard_error\": se_diff,\n",
    "        \"t_stat\": t_stat,\n",
    "        \"p_value\": p_value,\n",
    "        \"reject_h0\": reject_h0,\n",
    "        \"conclusion\": f\"Durability {category1} is at least {test_value} units larger than Durability {category2}\" if reject_h0 else f\"Insufficient evidence that Durability {category1} is at least {test_value} units larger than Durability {category2}\"\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "result = test_durability_difference(model, \"B\", \"A\", test_value=2)\n",
    "print(result.get(\"conclusion\"))\n",
    "result = test_durability_difference(model, \"A\", \"B\", test_value=2)\n",
    "print(result.get(\"conclusion\"))\n",
    "\n",
    "result = test_durability_difference(model, \"C\", \"A\", test_value=2)\n",
    "print(result.get(\"conclusion\"))\n",
    "result = test_durability_difference(model, \"A\", \"C\", test_value=2)\n",
    "print(result.get(\"conclusion\"))\n",
    "\n",
    "result = test_durability_difference(model, \"C\", \"B\", test_value=2)\n",
    "print(result.get(\"conclusion\"))\n",
    "result = test_durability_difference(model, \"B\", \"C\", test_value=2)\n",
    "print(result.get(\"conclusion\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
